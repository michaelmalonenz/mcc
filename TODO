Misc:
Should I be tokenising before I get to the preprocessor? (The tokens don't actually change, 
unless we have a ## in there!, but we could modify that one in places)
write a ruby script to replace all tri-graphs in c code OR
add in a compile-time switched ability to handle tri-graphs (so I can eventually claim full c99 compliance)
options
Use stopper for the unit tests??
As soon as possible, start eating my own dog food -> alongside gcc?

Unit Tests I really should write:
test_Macros  (Believed to be the source of the memory leaks, as I currently don't free the macros when I'm done!
test_Preprocessor

Should I also write some overall tests for the preprocessor section?

Preprocessor:
fix ifndef to work correctly
  - remove the file-scoped variables to handle conditionals (put them on the stack, for recursive goodness)
  - add in the "skip" variable to the logic deciding whether or not to ignore the conditional portion
change the macro definitions to be a hash table?  It seems unnecessarily limiting to do it this way.
Figure out how one goes about deleting the macro definitions correctly
make it run under valgrind again - it currently leaks like a seive (Less so now!)
Fix the /**/ style comments to allow for more than one set per line 
  - I don't want to sink to GOTO statements!
  - might need to rework the algorithm entirely??
  - Also need to allow for // style comments to come after a /**/ comment on a line
macro replacement
tokenise expressions - should this be passed off to the tokeniser?  The rules are slightly different...
evaluate macro expressions (like #if etc)
support function macros
Need to handle the ## operator

Tokeniser:
break a string into consecutive tokens

Parser:
Assert that the input file conforms to the c(99) standard

Assembler/linker - (Do I actually want to write this myself or should I attempt to write object files which are compatible with binutils' linker and use that?)
Do I want to distribute a C library (like uClibc or Newlib etc) with this? probably.
